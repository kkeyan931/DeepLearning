{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING ASSIGNMENT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Karthikeyan K 2018103549"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory of ANN\n",
    "\n",
    "An artificial neural network is a supervised learning algorithm which means that we provide it the input data containing the independent variables and the output data that contains the dependent variable. For instance, in our example our independent variables are X1, X2 and X3. The dependent variable is Y.\n",
    "\n",
    "In the beginning, the ANN makes some random predictions, these predictions are compared with the correct output and the error(the difference between the predicted values and the actual values) is calculated. The function that finds the difference between the actual value and the propagated values is called the cost function. The cost here refers to the error. Our objective is to minimize the cost function. Training a neural network basically refers to minimizing the cost function. We will see how we can perform this task.\n",
    "\n",
    "A neural network executes in two phases: Feed Forward phase and Back Propagation phase. Let us discuss both these steps in detail.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "#for calculating accuracy score for the model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is comprised of photos of dogs and cats provided as a subset of photos from a much larger dataset of \n",
    "anually annotated photos. The dataset was developed as a partnership between Petfinder.com and Microsoft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataSet is splitted into Train and Test. Train DataSet is used to train the Model and Test Dataset is used to Test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "\n",
    "    train_dataset = h5py.File('DataSets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
    "    \n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
    "    \n",
    "    test_dataset = h5py.File('DataSets/test_catvnoncat.h5', \"r\")\n",
    "    \n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
    "    \n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
    "    \n",
    "    classes = np.array(test_dataset[\"list_classes\"][:])\n",
    "\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], -1)/255.\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)/255.\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the DataSet into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dataFrame = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12278</th>\n",
       "      <th>12279</th>\n",
       "      <th>12280</th>\n",
       "      <th>12281</th>\n",
       "      <th>12282</th>\n",
       "      <th>12283</th>\n",
       "      <th>12284</th>\n",
       "      <th>12285</th>\n",
       "      <th>12286</th>\n",
       "      <th>12287</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.317647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.384314</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.556863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.007843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.082353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12288 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6      \\\n",
       "0  0.066667  0.121569  0.219608  0.086275  0.129412  0.231373  0.098039   \n",
       "1  0.768627  0.752941  0.745098  0.756863  0.729412  0.713725  0.737255   \n",
       "2  0.321569  0.278431  0.266667  0.349020  0.325490  0.325490  0.392157   \n",
       "3  0.003922  0.086275  0.007843  0.003922  0.054902  0.007843  0.003922   \n",
       "4  0.035294  0.035294  0.019608  0.039216  0.035294  0.023529  0.035294   \n",
       "\n",
       "      7         8         9      ...     12278     12279     12280     12281  \\\n",
       "0  0.137255  0.243137  0.098039  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.701961  0.682353  0.835294  ...  0.313725  0.325490  0.321569  0.317647   \n",
       "2  0.384314  0.407843  0.415686  ...  0.670588  0.603922  0.611765  0.627451   \n",
       "3  0.050980  0.003922  0.015686  ...  0.105882  0.113725  0.345098  0.196078   \n",
       "4  0.035294  0.023529  0.035294  ...  0.066667  0.054902  0.082353  0.050980   \n",
       "\n",
       "      12282     12283     12284     12285     12286     12287  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.329412  0.321569  0.321569  0.321569  0.313725  0.317647  \n",
       "2  0.572549  0.580392  0.596078  0.541176  0.552941  0.556863  \n",
       "3  0.054902  0.239216  0.101961  0.007843  0.231373  0.007843  \n",
       "4  0.039216  0.062745  0.039216  0.066667  0.121569  0.082353  \n",
       "\n",
       "[5 rows x 12288 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies sigmoid function to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "  \n",
    "  return 1/(1+np.power(np.e, -Z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigmoid prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies differentiation of sigmoid function to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_prime(Z):\n",
    "\n",
    "    return (1-np.power(Z, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to generate some output, the input data should be fed in the forward direction only. The data should not flow in reverse direction during output generation otherwise it would form a cycle and the output could never be generated. Such network configurations are known as feed-forward network. The feed-forward network helps in forward propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs forward propagation and calculates output value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, params):\n",
    "\n",
    "    w = params['w']\n",
    "    \n",
    "    b = params['b']\n",
    "    z = np.dot(X, w) + b\n",
    "    \n",
    "    a = sigmoid(z)\n",
    "\n",
    "    return {'z': z, 'a': a}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is the essence of neural network training. It is the method of fine-tuning the weights of a neural network based on the error rate obtained in the previous epoch (i.e., iteration). Proper tuning of the weights allows you to reduce error rates and make the model reliable by increasing its generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs backward propagation and calculates dw and db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(X, y, cache):\n",
    "\n",
    "    z = cache['z']\n",
    "    \n",
    "    a = cache['a']\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    dz = a - y\n",
    "    dw = (1./m)*np.dot(X.T, dz)\n",
    "    \n",
    "    db = (1./m)*np.sum(dz)\n",
    "\n",
    "    #Dictionary containing gradients 'dz', 'dw' and 'db'\n",
    "\n",
    "    return {'dz': dz, 'dw': dw, 'db': db}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the weights of the layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updates weights of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(params, changes, learning_rate=0.01):\n",
    "\n",
    "    w = params['w']\n",
    "    b = params['b']\n",
    "    dw = changes['dw']\n",
    "    db = changes['db']\n",
    "\n",
    "    w -= learning_rate*dw\n",
    "    b -= learning_rate*db\n",
    "\n",
    "    #Dictionary containing updated weights and biases\n",
    "    #The keys for weights and bias arrays in the dict is 'w' and 'b'\n",
    "\n",
    "    return {'w': w, 'b': b}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(cache, y):\n",
    "\n",
    "    a = cache['a']\n",
    "    m = y.shape[0]\n",
    "    return -1/m*np.sum(xlogy(y, a) + xlogy(1-y, 1-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes random weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_nn(X):\n",
    "\n",
    "    np.random.seed(999)\n",
    "\n",
    "    w = np.random.randn(X.shape[1], 1) * 0.01\n",
    "    b = 0\n",
    "\n",
    "    return {'w': w, 'b': b}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 12288)\n",
      "(209, 1)\n",
      "(50, 12288)\n",
      "(50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch\n",
    "\n",
    "In terms of artificial neural networks, an epoch refers to one cycle through the full training dataset. Usually, training a neural network takes more than a few epochs. In other words, if we feed a neural network the training data for more than one epoch in different patterns, we hope for a better generalization when given a new \"unseen\" input (test data). An epoch is often mixed up with an iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate\n",
    "\n",
    "In machine learning and statistics, the learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function. Since it influences to what extent newly acquired information overrides old information, it metaphorically represents the speed at which a machine learning model \"learns\". In the adaptive control literature, the learning rate is commonly referred to as gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch is set to 1000 and Learning Rate is set to 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "learning_rate = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tLoss:0.72463\tTraining accuracy:0.45455\tTesting accuracy:0.34000\n",
      "Epoch: 100\tLoss:0.58224\tTraining accuracy:0.68421\tTesting accuracy:0.34000\n",
      "Epoch: 200\tLoss:0.46335\tTraining accuracy:0.81818\tTesting accuracy:0.44000\n",
      "Epoch: 300\tLoss:0.37246\tTraining accuracy:0.89952\tTesting accuracy:0.62000\n",
      "Epoch: 400\tLoss:0.32947\tTraining accuracy:0.91866\tTesting accuracy:0.70000\n",
      "Epoch: 500\tLoss:0.30155\tTraining accuracy:0.92823\tTesting accuracy:0.72000\n",
      "Epoch: 600\tLoss:0.27835\tTraining accuracy:0.93780\tTesting accuracy:0.74000\n",
      "Epoch: 700\tLoss:0.25866\tTraining accuracy:0.94258\tTesting accuracy:0.74000\n",
      "Epoch: 800\tLoss:0.24167\tTraining accuracy:0.95694\tTesting accuracy:0.74000\n",
      "Epoch: 900\tLoss:0.22683\tTraining accuracy:0.96172\tTesting accuracy:0.76000\n"
     ]
    }
   ],
   "source": [
    "params = initialize_nn(X_train)\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    cache = forward_prop(X_train, params)\n",
    "    \n",
    "    loss = calculate_loss(cache, y_train)\n",
    "    \n",
    "    updates = backward_prop(X_train, y_train, cache)\n",
    "    \n",
    "    params = update_weights(params, updates, learning_rate=learning_rate)\n",
    "\n",
    "    if i%(epochs/10) == 0:\n",
    "        \n",
    "        print('Epoch: {}\\tLoss:{:.5f}'.format(i, loss), end='')\n",
    "        train_cache = np.where(cache['a']>0.5, 1, 0)\n",
    "        \n",
    "        print('\\tTraining accuracy:{:.5f}'.format(accuracy_score(y_train, train_cache)), end='')\n",
    "        test_cache = forward_prop(X_test, params)['a']\n",
    "        \n",
    "        test_cache = np.where(test_cache>=0.5, 1, 0)\n",
    "        \n",
    "        print('\\tTesting accuracy:{:.5f}'.format(accuracy_score(y_test, test_cache)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
